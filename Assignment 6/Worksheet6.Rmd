---
title: "Worksheet6"
author: "STAT414"
date: "2024-10-19"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# #This worksheet, is based on the Module06 material, but also draws on your knowledge from
# previous modules, especially Module05. Main event here is the introduction of a super useful and
# widely used technique called ”Bootstrapping” to estimate standard errors (and in general, sampling
# distributions) of estimators, without making any distributional assumptions on the population. 
# After the simulation technique you learned in Module03, bootstrapping is perhaps the most important
# skill you are picking up in this course. Happy bootstrapping!

library(EnvStats)
TcCB <- EPA.94b.tccb.df
head(TcCB)

TcCB.Ref <- TcCB[TcCB$Area == "Reference",]
TcCB.Cleanup <- TcCB[TcCB$Area == "Cleanup",]

head(TcCB.Ref)
head(TcCB.Cleanup)

# 1. Determine if we can comfortably assume a theoretical model for each of the above variables.

# (a) Plot the histogram of the data, and overlay a log-normal curve.

hist(TcCB.Ref$TcCB, probability=TRUE, main = "Histogram of TcCB.Ref, with log-normal curve",
     xlab="TcCB", xlim=c(0,1.5))
lines(density(TcCB.Ref$TcCB), col = 2, lwd = 2)
#log-normal = lnorm
curve(dlnorm(x, mean=mean(log(TcCB.Ref$TcCB)), sd=sd(log(TcCB.Ref$TcCB))), 
      lwd=2, col="blue", add=TRUE)

#Ignore the extreme outliers in the TcCB.Cleanup data by setting xlim=c(0,7), which
#would otherwise greatly imbalance the histogram to be unreadable
hist(TcCB.Cleanup$TcCB, probability=TRUE, main = "Histogram of TcCB.Cleanup, with log-normal curve",
     xlab="TcCB", xlim=c(0,7), breaks=c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,
                                          1,1.2,1.3,1.4,1.5,3,6,9,12,15,200))
lines(density(TcCB.Cleanup$TcCB), col = 2, lwd = 2)
#log-normal = lnorm
curve(dlnorm(x, mean=mean(log(TcCB.Cleanup$TcCB)), sd=sd(log(TcCB.Cleanup$TcCB))),
      lwd=2, col="blue", add=TRUE)


# (b) Use the function gofTest() of EnvStats to test the log-normality assumption of the
# data for each variable.
gofTest(TcCB.Ref$TcCB, dist = "lnorm")
gofTest(TcCB.Cleanup$TcCB, dist = "lnorm")

# (c) State your conclusions.
cat("The histograms are mostly inconclusive when comparing the density curves to
    the superimposed log-normal curves. They are both similar in pattern and shape
    to the log-normal curves, but the margins are not correct and there are many 
    noticeable devations. However, from the gofTest for both datasets for the log-normal
    distribution, choose a significance level of 0.05, and the calculated p-values
    for Ref and Cleanup are: 0.5371935 and ~0.0000013, repspectively. 
    0.5371935 is mucher greater than .05, and 0.0000013 is much smaller than .05,
    therefore we can conclude that there is strong evidence to suggest that the 
    TcCB data for entries that have Area==Reference do not follow the log-normal 
    distribution, and that there is strong support that the TcCB data for entries that 
    have Area==Cleanup do follow log-normal distribution.")

# 2. Apply the log transformation to each of the above variable and create
ln.TcCB.Ref <- log(TcCB.Ref$TcCB)
ln.TcCB.Cleanup <- log(TcCB.Ref$TcCB)

# (a) Use the appropriately modified version of the Bootstrapping code provided to obtain
# estimates of the mean [= mu = E(log(X))] for each variable and corresponding bootstrap
# standard errors.

cat("The basic steps of the bootstrap are:
      1. Estimate the parameter based on the data.
      2. Sample the data with replacement B times, and each
          time estimate the parameter based on this bootstrap
          sample.
      3. Use the estimated parameter created in Step 1 and the
          bootstrap estimate of the sampling distribution of the
          estimator created in Step 2 to obtain the standard
          error for the parameter.
")

#Step 1 - Estimate population - Already done above
#Step 2 - Perform bootstrapping, draw samples from data using original sampling method

set.seed(1)
strap_size <- 10000

results_ref_means <- c()
results_cleanup_means <- c()

#Replace sample to generate bootstraps
for(i in 1:strap_size){
  refsample <- sample(ln.TcCB.Ref, size=length(ln.TcCB.Ref), replace=TRUE)
  cleanupsample <- sample(ln.TcCB.Cleanup, size=length(ln.TcCB.Cleanup), replace=TRUE)
  
  results_ref_means[i] <- mean(refsample)
  results_cleanup_means[i] <- mean(cleanupsample)
}

#Calculate mean of each and the bootstrap standard errors (SD)
refmean <- mean(results_ref_means) 
refse <- sd(results_ref_means)
cat("Bootstrap mean of ln.TcCB.ref:", refmean)
cat("Bootstrap standard error of ln.TcCB.ref:", refse)

cleanupmean <- mean(results_cleanup_means) 
cleanupse <- sd(results_cleanup_means)
cat("Bootstrap mean of ln.TcCB.cleanup:", cleanupmean)
cat("Bootstrap standard error of ln.TcCB.cleanup:", cleanupse)

# (b) Compare the above SE’s to the corresponding s/sqrt(n), and comment on how close they are.
ref_normal_se <- sd(ln.TcCB.Ref) / sqrt(length(ln.TcCB.Ref))
cleanup_normal_se <- sd(ln.TcCB.Cleanup) / sqrt(length(ln.TcCB.Cleanup))

cat("Normal ln.TcCB.Reference SE:", ref_normal_se)
cat("Normal ln.TcCB.Cleanup SE:", cleanup_normal_se)

cat("The normal standard errors of both datasets are very close to their bootstrap 
    standard errors, within a ~0.03 margin. This suggests that the log-transformed
    TcCB datasets are approximately following a normal distribution, which we 
    were able to calculate without any knowledge of underlying distributions, using
    bootstrapping.")

```